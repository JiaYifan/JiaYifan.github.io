!> 涉及面试题：为什么 0.1 + 0.2 != 0.3？如何解决这个问题？

答：JS 的 `number` 类型是浮点类型，而 JS 采用 IEEE 754 双精度版本（64位），所以在计算小数运算时，会先将十进制的小数换算到对应的二进制，一部分小数并不能完整的换算为二进制，因此出现了误差。

注：例如`0.1.toString(2)`得到"0.0001100110011001100110011001100110011001100110011001101"，可以0.1的二进制其实包含一个 `0011` 循环，因此无法用64位二进制精确计算。

扩展：细心的同学会发现，`0.3+0.1 === 0.4 //true; 0.1+0.1 === 0.2 // true`，这是因为在`0.1 + 0.2`这个式子中，`0.1`和`0.2`都是近似表示的，在他们相加的时候，两个近似值进行了计算，导致最后得到的值是`0.30000000000000004`，此时对于JS来说，其不够近似于`0.3`，于是就出现了`0.1 + 0.2 != 0.3`这个现象。 当然，也并非所有的近似值相加都得不到正确的结果。

半解：所以有人简单利用近似值来解决这个问题`parseFloat((0.1 + 0.2).toFixed(10)) === 0.3 // true`，但是如若真的需要计算`0.10000000000000001+0.2`，`(0.10000000000000001+0.2).toFixed(10) // "0.3000000000"`岂不造成精度丢失？

全解：
```javascript

```